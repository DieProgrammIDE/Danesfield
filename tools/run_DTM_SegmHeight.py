#!/usr/bin/env python

'''
Run the DTM and segment by height parts of the Danesfield processing pipeline.
'''

import argparse
import datetime
import glob
import logging
import os
import re
import subprocess
import sys
from pathlib import Path


def create_working_dir(working_dir, imagery_dir):
    '''
    Create working directory for running algorithms
    All files generated by the system are written to this directory.

    :param working_dir: Directory to create for work. Cannot be a subdirectory of `imagery_dir`.
    This is to avoid adding the work images to the pipeline when traversing the `imagery_dir`.
    :type working_dir: str

    :param imagery_dir: Directory where imagery is stored.
    :type imagery_dir: str

    :raises ValueError: If `working_dir` is a subdirectory of `imagery_dir`.
    '''
    if not working_dir:
        date_str = str(datetime.datetime.now().timestamp())
        working_dir = 'danesfield-' + date_str.split('.')[0]
    if not os.path.isdir(working_dir):
        os.makedirs(working_dir, exist_ok=True)
    if imagery_dir and os.path.realpath(imagery_dir) in os.path.realpath(working_dir):
        raise ValueError('The working directory ({}) is a subdirectory of the imagery directory '
                         '({}).'.format(working_dir, imagery_dir))
    return working_dir


def ensure_complete_modality(modality_dict, require_rpc=False):
    '''
    Ensures that a certain modality (MSI, PAN, SWIR) has all of the required files for computation
    through the whole pipeline.

    :param modality_dict: Mapping of a certain modality to its image, rpc, and info files.
    :type modality_dict: dict

    :param require_rpc: Whether or not to consider the rpc file being present as a requirement for
    a complete modality.
    :type require_rpc: bool
    '''
    keys = ['image', 'info']
    if require_rpc:
        keys.append('rpc')
    return all(key in modality_dict for key in keys)


def collate_input_paths(paths):
    '''
    Collate a list of input file paths into a dictionary.  Considers
    the files identifier, modality, and extension.

    :param paths: List of input files paths to collate
    :type paths: enumerable
    '''
    input_re = re.compile(r'(?P<gra>GRA_)?.*'
                          '(?P<prefix>[0-9]{2}[A-Z]{3}[0-9]{8})\-'
                          '(?P<modality>P1BS|M1BS|A1BS)\-'
                          '(?P<trail>[0-9]{12}_[0-9]{2}_P[0-9]{3}).*'
                          '(?P<ext>\..+)$')

    modality_map = {'P1BS': 'pan',
                    'M1BS': 'msi',
                    'A1BS': 'swir'}

    out_collection = {}
    for path in paths:
        # Match on upper-case path
        match = input_re.match(os.path.basename(path).upper())
        if match:
            key = '%s-%s' % (match.group('prefix'), match.group('trail'))
            modality = modality_map[match.group('modality')]
            if key not in out_collection:
                out_collection[key] = {modality: {}}
            elif modality not in out_collection[key]:
                out_collection[key][modality] = {}

            if match.group('gra') is not None and \
               match.group('ext').endswith('.RPC'):
                out_collection[key][modality]['rpc'] = path
            elif match.group('ext').endswith('.NTF'):
                out_collection[key][modality]['image'] = path
            elif match.group('ext').endswith('.TAR'):
                out_collection[key][modality]['info'] = path

    return out_collection


# Get path to tool relative to this (run_danesfield.py)
def relative_tool_path(rel_path):
    return os.path.join(os.path.dirname(os.path.realpath(__file__)), rel_path)


# Helper for building the python command.  The '-u' option tells
# python not to buffer IO
def py_cmd(tool_path):
    return ['python', '-u', tool_path]


def run_step(working_dir, step_name, command, abort_on_error=True, skip_complete=False):
    '''
    Runs a command if it has not already been run successfully.  Log
    and exit status files are written to `working_dir`.  This script
    will exit(1) if the command's exit status is anything but 0, and
    if `abort_on_error` is True.

    The stdout and stderr of the command are both printed to stdout
    and written to the log file.

    :param working_dir: Directory to create for log and exit status
    output files.
    :type working_dir: str

    :param step_name: Nominal identifier for the step.
    :type step_name: str

    :param command: Command passed directly to `subprocess.Popen`.
    :type command: array or str

    :param abort_on_error: If True, the program will exit if the step
    fails.  Default is True.
    :type abort_on_error: bool
    '''
    # Path to the log file, which will include both the stdout and
    # stderr from the step command
    step_log_fpath = os.path.join(working_dir, '{}.log'.format(step_name))
    # Empty file to indicate the exit status (return code) of the step
    # command.  The exit status is appended to this prefix before
    # creation
    step_returncode_fpath_prefix = os.path.join(working_dir,
                                                '{}.exitstatus'.format(step_name))

    # Check that we haven't already successfully completed this step
    # (as indicated by an exit status of 0)
    if (not skip_complete) and os.path.isfile('{}.0'.format(step_returncode_fpath_prefix)):
        return 0
    else:
        # If we haven't run the step, or a previous run failed, remove
        # previous log and returncode files
        if os.path.isfile(step_log_fpath):
            os.remove(step_log_fpath)
        for f in glob.glob('{}.*'.format(step_returncode_fpath_prefix)):
            os.remove(f)

        # Create step working directory if it didn't already exist
        if not os.path.isdir(working_dir):
            os.makedirs(working_dir, exist_ok=True)

        logging.info('---- Running step: {} ----'.format(step_name))
        logging.debug(command)
        # Run the step; newline buffered text
        proc = subprocess.Popen(command,
                                stderr=subprocess.STDOUT,
                                stdout=subprocess.PIPE,
                                universal_newlines=True,
                                bufsize=1)

        # Write the output/err both to stdout and the log file
        with open(step_log_fpath, 'w') as out_f:
            for line in proc.stdout:
                print(line, end='')
                print(line, end='', file=out_f)

        # Wait for the process to terminate and set the return code
        # (max of 5 seconds)
        proc.wait(timeout=5)
        Path('{}.{}'.format(step_returncode_fpath_prefix, proc.returncode)).touch()

        if abort_on_error and proc.returncode != 0:
            logging.error('---- Error on step: {}. Aborting! ----'.format(step_name))
            exit(1)

        return proc.returncode


def main(args):
    parser = argparse.ArgumentParser(description=__doc__,
                                     formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('working_dir', help='path/to/working/directory')
    parser.add_argument('aoi_name', help='area of interest')
    parser.add_argument('dsm_file', help='path/to/DSM/file_P3D_DSM.tif')
    parser.add_argument('--skip_complete', action='store_true',
                        help='skip check complete step status?')
    parser.add_argument('--tension', metavar='T', type=int, default=15,
                        help='Number of inner smoothing iterations for DTM, '
                             'greater values increase surface tension; default=%(default)s')
    args = parser.parse_args(args)

    working_dir = args.working_dir
    aoi_name = args.aoi_name
    dsm_file = args.dsm_file

### fit DTM to the DSM
    fit_dtm_outdir = os.path.join(working_dir, 'fit-dtm')
    dtm_file = os.path.join(fit_dtm_outdir, aoi_name + f'_DTM.t{args.tension}.tif')

    cmd_args = py_cmd(relative_tool_path('fit_dtm.py'))
    # NOTE -t 12 and below produce holes in roofs for short buildings
    cmd_args += [dsm_file, dtm_file, f'--tension={args.tension}']

    run_step(fit_dtm_outdir,
             'fit-dtm',
             cmd_args,
             skip_complete=args.skip_complete)

### segment-by-height
    seg_by_height_outdir = os.path.join(working_dir, 'segment-by-height')
    threshold_output_mask_fpath = os.path.join(seg_by_height_outdir, f'threshold_CLS.t{args.tension}.tif')
    cmd_args = py_cmd(relative_tool_path('segment_by_height.py'))
    cmd_args += [dsm_file,
                 dtm_file,
                 threshold_output_mask_fpath]
    run_step(seg_by_height_outdir,
             'segment-by-height',
             cmd_args,
             skip_complete=args.skip_complete)


if __name__ == '__main__':
    loglevel = os.environ.get('LOGLEVEL', 'INFO').upper()
    logging.basicConfig(level=loglevel)
    main(sys.argv[1:])
